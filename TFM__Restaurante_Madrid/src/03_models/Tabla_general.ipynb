{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aa82ca7-1dc3-440f-9567-26eacc9e9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ B1 cargado y procesado.\n",
      "‚úÖ B2 cargado y procesado.\n",
      "‚úÖ B3 cargado y procesado.\n",
      "‚úÖ B4 cargado y procesado.\n",
      "‚úÖ B5 cargado y procesado.\n",
      "‚úÖ B6 cargado y procesado.\n",
      "‚úÖ B7 cargado y procesado.\n",
      "‚úÖ B8 cargado y procesado.\n",
      "‚úÖ B9 cargado y procesado.\n",
      "\n",
      "--- PROCESO COMPLETADO ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1. RE-CONFIRMACI√ìN DE RUTAS\n",
    "# Aseg√∫rate de que esta ruta es la que te funcion√≥ antes\n",
    "DATA_DIR = r\"C:\\Users\\kacam\\TFM\\ML - Ranking\\Tablas\"\n",
    "WGS84 = \"EPSG:4326\"\n",
    "UTM30N = \"EPSG:25830\"\n",
    "\n",
    "# Diccionario de archivos\n",
    "paths = {\n",
    "    \"B1\": os.path.join(DATA_DIR, \"B1_Restaurantes_2025_Lat_Long_CLEAN.csv\"),\n",
    "    \"B2\": os.path.join(DATA_DIR, \"B2_Menu_RestaurantesMX_LIMPIO.csv\"),\n",
    "    \"B3\": os.path.join(DATA_DIR, \"B3_Restaurantes_Terrazas_2025_Lat_Long_LIMPIO.csv\"),\n",
    "    \"B4\": os.path.join(DATA_DIR, \"B4_Flujo_Peatones_2024_LIMPIO.csv\"),\n",
    "    \"B5\": os.path.join(DATA_DIR, \"B5_Licencias_2025_Lat_Long_LIMPIO.csv\"),\n",
    "    \"B6\": os.path.join(DATA_DIR, \"B6_Residentes_Edad_Nacionalidad_2025_LIMPIO.csv\"),\n",
    "    \"B7\": os.path.join(DATA_DIR, \"B7_Poblacion_Madrid_LIMPIO_v2.csv\"),\n",
    "    \"B8\": os.path.join(DATA_DIR, \"B8_Aparcamientos_Publicos.xlsx\"),\n",
    "    \"B9\": os.path.join(DATA_DIR, \"B9_Estaciones_Metro_Renfe_CLEAN.csv\"),\n",
    "}\n",
    "\n",
    "# 2. FUNCI√ìN DE CARGA Y CONVERSI√ìN AUTOM√ÅTICA\n",
    "def load_to_gdf(name, path):\n",
    "    # Carga el archivo\n",
    "    if path.endswith('.csv'):\n",
    "        df = pd.read_csv(path, encoding='utf-8')\n",
    "    else:\n",
    "        df = pd.read_excel(path)\n",
    "    \n",
    "    # Identifica columnas de coordenadas\n",
    "    cols = df.columns.tolist()\n",
    "    lat_col = next((c for c in cols if c.lower() in ['latitud', 'lat_num', 'lat', 'latitude']), None)\n",
    "    lon_col = next((c for c in cols if c.lower() in ['longitud', 'lon_num', 'lon', 'longitude']), None)\n",
    "    \n",
    "    if lat_col and lon_col:\n",
    "        df = df.dropna(subset=[lat_col, lon_col])\n",
    "        # Limpieza de caracteres si vienen como string con comas\n",
    "        df[lat_col] = pd.to_numeric(df[lat_col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "        df[lon_col] = pd.to_numeric(df[lon_col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "        df = df.dropna(subset=[lat_col, lon_col])\n",
    "        \n",
    "        geometry = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=WGS84)\n",
    "        return gdf.to_crs(UTM30N)\n",
    "    else:\n",
    "        # Si no tiene coordenadas (como B2 o B6 que son tablas de datos), devolvemos el DataFrame\n",
    "        return df\n",
    "\n",
    "# 3. EJECUCI√ìN\n",
    "gdfs = {}\n",
    "for name, path in paths.items():\n",
    "    if os.path.exists(path):\n",
    "        gdfs[name] = load_to_gdf(name, path)\n",
    "        print(f\"‚úÖ {name} cargado y procesado.\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name} no encontrado en la ruta.\")\n",
    "\n",
    "print(\"\\n--- PROCESO COMPLETADO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebeb9b0c-6a24-42bb-985a-2707cb9e1ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß± Grid generado: 36292 celdas con Lat/Lon listas para dibujo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacam\\AppData\\Local\\Temp\\ipykernel_16188\\572615148.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  grid['lat_center'] = grid_wgs84.geometry.centroid.y\n",
      "C:\\Users\\kacam\\AppData\\Local\\Temp\\ipykernel_16188\\572615148.py:19: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  grid['lon_center'] = grid_wgs84.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "\n",
    "# Creamos el √°rea de estudio basada en los restaurantes (B1)\n",
    "xmin, ymin, xmax, ymax = gdfs[\"B1\"].total_bounds\n",
    "cell_size = 150 # metros\n",
    "\n",
    "# Generar la malla\n",
    "cols = list(np.arange(xmin, xmax + cell_size, cell_size))\n",
    "rows = list(np.arange(ymin, ymax + cell_size, cell_size))\n",
    "polygons = [box(x, y, x + cell_size, y + cell_size) for x in cols for y in rows]\n",
    "\n",
    "grid = gpd.GeoDataFrame({'geometry': polygons}, crs=UTM30N)\n",
    "grid['grid_id'] = [f\"cell_{i:06d}\" for i in range(len(grid))]\n",
    "\n",
    "# --- AQU√ç GUARDAMOS LAS COORDENADAS PARA TU MAPA ---\n",
    "grid_wgs84 = grid.to_crs(WGS84)\n",
    "grid['lat_center'] = grid_wgs84.geometry.centroid.y\n",
    "grid['lon_center'] = grid_wgs84.geometry.centroid.x\n",
    "\n",
    "print(f\"üß± Grid generado: {len(grid)} celdas con Lat/Lon listas para dibujo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "332af300-1e74-4607-a91b-3d606fa15d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones espaciales cargadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "def count_points_within(gdf_points, centers, radius_m):\n",
    "    \"\"\"Cuenta puntos dentro de un radio alrededor de centroides de forma eficiente\"\"\"\n",
    "    if gdf_points is None or len(gdf_points) == 0:\n",
    "        return pd.Series(0, index=centers.index)\n",
    "    \n",
    "    # Creamos un √°rea de influencia (buffer) en metros\n",
    "    # Usamos centers.apply para mayor precisi√≥n celda a celda\n",
    "    return centers.apply(lambda c: gdf_points.within(c.buffer(radius_m)).sum())\n",
    "\n",
    "def min_dist(points_gdf, centers):\n",
    "    \"\"\"Calcula la distancia al punto m√°s cercano\"\"\"\n",
    "    if points_gdf is None or len(points_gdf) == 0:\n",
    "        return pd.Series(np.nan, index=centers.index)\n",
    "    return centers.apply(lambda c: points_gdf.distance(c).min())\n",
    "\n",
    "def normalize_minmax(s):\n",
    "    \"\"\"Normaliza una serie entre 0 y 1\"\"\"\n",
    "    if s.max() == s.min():\n",
    "        return s * 0\n",
    "    return (s - s.min()) / (s.max() - s.min())\n",
    "\n",
    "print(\"‚úÖ Funciones espaciales cargadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c740b978-4b7d-43d9-9e9a-cf413fd0e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos y funciones listos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Recargamos dfs si se ha perdido (aseg√∫rate de que DATA_DIR est√© definido)\n",
    "dfs = {}\n",
    "for k, p in paths.items():\n",
    "    if p.endswith('.csv'):\n",
    "        dfs[k] = pd.read_csv(p, encoding='utf-8')\n",
    "    else:\n",
    "        dfs[k] = pd.read_excel(p)\n",
    "\n",
    "# 2. Re-definimos las funciones por si acaso\n",
    "def count_points_within(gdf_points, centers, radius_m):\n",
    "    if gdf_points is None or len(gdf_points) == 0: return pd.Series(0, index=centers.index)\n",
    "    return centers.apply(lambda c: gdf_points.within(c.buffer(radius_m)).sum())\n",
    "\n",
    "def normalize_minmax(s):\n",
    "    if s.max() == s.min(): return s * 0\n",
    "    return (s - s.min()) / (s.max() - s.min())\n",
    "\n",
    "print(\"‚úÖ Datos y funciones listos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63c38f46-bde2-4d8e-a8f4-fc160e62d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cent = grid.geometry.centroid\n",
    "\n",
    "# 1. Variables Base\n",
    "grid[\"rest_total_500m\"] = count_points_within(gdfs[\"B1\"], cent, 500)\n",
    "grid[\"terrazas_500m\"] = count_points_within(gdfs[\"B3\"], cent, 500)\n",
    "grid[\"licencias_500m\"] = count_points_within(gdfs[\"B5\"], cent, 500)\n",
    "\n",
    "# 2. Identificaci√≥n de Mexicanos (B1 + B2)\n",
    "# Buscamos la columna de ID en B2 de forma flexible\n",
    "col_id_b2 = next((c for c in dfs[\"B2\"].columns if c.lower() in ['id_local', 'id', 'id_restaurante']), None)\n",
    "col_id_b1 = next((c for c in gdfs[\"B1\"].columns if c.lower() in ['id_local', 'id', 'id_restaurante']), None)\n",
    "\n",
    "if col_id_b2 and col_id_b1:\n",
    "    mx_ids = dfs[\"B2\"][col_id_b2].unique()\n",
    "    gdf_mx = gdfs[\"B1\"][gdfs[\"B1\"][col_id_b1].isin(mx_ids)]\n",
    "    grid[\"mx_rest_total_500m\"] = count_points_within(gdf_mx, cent, 500)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se pudo cruzar B1 con B2 por falta de ID. Usando 0 para mx_rest.\")\n",
    "    grid[\"mx_rest_total_500m\"] = 0\n",
    "\n",
    "# 3. Penalizaci√≥n por Saturaci√≥n (L√≥gica de Negocio)\n",
    "def saturation_penalty(mx_count):\n",
    "    if mx_count <= 2: return 1.0  # Zona ideal (cl√∫ster saludable)\n",
    "    if mx_count <= 4: return 0.7  # Riesgo de saturaci√≥n\n",
    "    return 0.4                   # Saturaci√≥n alta: el score cae\n",
    "\n",
    "grid[\"penalty_sat\"] = grid[\"mx_rest_total_500m\"].apply(saturation_penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a8f7122-492c-4c73-9d41-54c0e9c40eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO GENERACI√ìN DEL DATASET BLINDADO V7.1...\n",
      "üìç Cruzando Grid con Distritos...\n",
      "   -> Distritos asignados. Celdas listas: 36292\n",
      "üè† Asignando Poblaci√≥n...\n",
      "‚öôÔ∏è Calculando densidades (Terrazas, Licencias)...\n",
      "üö∂ Calculando Peatones...\n",
      "üéØ Calculando Score Objetivo...\n",
      "\n",
      "‚úÖ ¬°√âXITO! Dataset generado: Dataset_Madrid_Model_Blind_V8.csv\n",
      "   - Filas totales: 36292\n",
      "   - Filas con Score > 0: 3984\n",
      "   - Media de Terrazas: 6.04\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üöÄ INICIANDO GENERACI√ìN DEL DATASET BLINDADO V7.1...\")\n",
    "\n",
    "# --- 1. FUNCI√ìN DE LIMPIEZA AGRESIVA ---\n",
    "def safe_clean(gdf):\n",
    "    \"\"\"Elimina columnas de sistema que rompen los sjoin\"\"\"\n",
    "    if gdf is None: return None\n",
    "    cols_to_drop = ['index_right', 'index_left']\n",
    "    return gdf.drop(columns=[c for c in cols_to_drop if c in gdf.columns], errors='ignore').to_crs(\"EPSG:25830\")\n",
    "\n",
    "# Limpieza inicial de todas las capas\n",
    "grid_m = safe_clean(grid)\n",
    "b1_m = safe_clean(gdfs[\"B1\"])\n",
    "b3_m = safe_clean(gdfs[\"B3\"])\n",
    "b4_m = safe_clean(gdfs[\"B4\"])\n",
    "b5_m = safe_clean(gdfs[\"B5\"])\n",
    "\n",
    "# --- 2. ASIGNACI√ìN DE DISTRITO (Con Limpieza Inmediata) ---\n",
    "print(\"üìç Cruzando Grid con Distritos...\")\n",
    "b1_ref = b1_m[['desc_distrito_local', 'geometry']].copy().dropna()\n",
    "\n",
    "# SJOIN\n",
    "grid_m = gpd.sjoin(grid_m, b1_ref, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# ¬°LIMPIEZA CR√çTICA AQU√ç! Borramos index_right inmediatamente\n",
    "grid_m = safe_clean(grid_m) \n",
    "\n",
    "# Procesamos nombres\n",
    "grid_m['distrito_join'] = grid_m['desc_distrito_local'].astype(str).str.upper().str.strip()\n",
    "grid_m = grid_m.drop_duplicates(subset=['grid_id'])\n",
    "\n",
    "print(f\"   -> Distritos asignados. Celdas listas: {len(grid_m)}\")\n",
    "\n",
    "# --- 3. ASIGNACI√ìN DE POBLACI√ìN (B7) ---\n",
    "print(\"üè† Asignando Poblaci√≥n...\")\n",
    "df_b7 = dfs[\"B7\"].copy()\n",
    "df_b7['distrito_join'] = df_b7['distrito'].astype(str).str.upper().str.strip()\n",
    "\n",
    "# Mapa de poblaci√≥n por distrito\n",
    "pop_map = df_b7.groupby('distrito_join')['num_personas'].sum().to_dict()\n",
    "cells_per_dist = grid_m['distrito_join'].value_counts().to_dict()\n",
    "\n",
    "# Funci√≥n de reparto segura\n",
    "def get_pop(d):\n",
    "    return pop_map.get(d, 0) / cells_per_dist.get(d, 1) if d in pop_map else 0\n",
    "\n",
    "grid_m['poblacion_estimada'] = grid_m['distrito_join'].apply(get_pop)\n",
    "\n",
    "# --- 4. VARIABLES DE CONTEXTO (Funci√≥n Blindada) ---\n",
    "print(\"‚öôÔ∏è Calculando densidades (Terrazas, Licencias)...\")\n",
    "\n",
    "def count_in_radius_safe(points_gdf, grid_gdf, radius=500):\n",
    "    # Limpiamos AMBOS dataframes antes de tocar nada\n",
    "    pts = safe_clean(points_gdf)\n",
    "    centers = safe_clean(grid_gdf).copy() # Copia limpia\n",
    "    \n",
    "    # Creamos buffer\n",
    "    centers['geometry'] = centers.geometry.centroid.buffer(radius)\n",
    "    \n",
    "    # Join seguro\n",
    "    joined = gpd.sjoin(pts, centers, how=\"inner\", predicate=\"within\")\n",
    "    \n",
    "    return joined.groupby(\"grid_id\").size()\n",
    "\n",
    "# Ejecutamos los conteos\n",
    "grid_m['terrazas_500m'] = grid_m['grid_id'].map(count_in_radius_safe(b3_m, grid_m)).fillna(0)\n",
    "grid_m['licencias_500m'] = grid_m['grid_id'].map(count_in_radius_safe(b5_m, grid_m)).fillna(0)\n",
    "grid_m['rest_total_500m'] = grid_m['grid_id'].map(count_in_radius_safe(b1_m, grid_m)).fillna(0)\n",
    "\n",
    "# --- 5. PEATONES (B4) ---\n",
    "print(\"üö∂ Calculando Peatones...\")\n",
    "# Agrupar por ubicaci√≥n √∫nica para no duplicar sensores\n",
    "b4_unique = b4_m.groupby('geometry')['cantidad_peatones'].mean().reset_index()\n",
    "b4_unique = gpd.GeoDataFrame(b4_unique, geometry='geometry', crs=\"EPSG:25830\")\n",
    "\n",
    "# Usamos la funci√≥n de conteo para saber cu√°ntos sensores hay cerca\n",
    "# (Si quieres sumar el valor del flujo, habr√≠a que hacer un sjoin espec√≠fico, \n",
    "#  pero para el modelo, la \"intensidad peatonal\" se puede inferir del conteo y del score final)\n",
    "centers_temp = safe_clean(grid_m).copy()\n",
    "centers_temp['geometry'] = centers_temp.geometry.centroid.buffer(500)\n",
    "joined_b4 = gpd.sjoin(b4_unique, centers_temp, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Sumamos el valor de flujo, no solo contamos puntos\n",
    "grid_m['peatones_val'] = grid_m['grid_id'].map(joined_b4.groupby(\"grid_id\")['cantidad_peatones'].sum()).fillna(0)\n",
    "\n",
    "# --- 6. SCORE FINAL (TARGET) ---\n",
    "print(\"üéØ Calculando Score Objetivo...\")\n",
    "def norm(s):\n",
    "    return (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "\n",
    "grid_m['score_final'] = (\n",
    "    0.5 * norm(grid_m['peatones_val']) + \n",
    "    0.5 * norm(grid_m['poblacion_estimada'])\n",
    ").clip(0, 1)\n",
    "\n",
    "# --- 7. EXPORTACI√ìN ---\n",
    "# Variables PROHIBIDAS para el entrenamiento (Leakage) -> peatones_val, poblacion_estimada\n",
    "# Variables PERMITIDAS -> terrazas_500m, licencias_500m, rest_total_500m, dist_metro (si la tienes)\n",
    "\n",
    "output_file = \"Dataset_Madrid_Model_Blind_V7.csv\"\n",
    "grid_m.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ ¬°√âXITO! Dataset generado: {output_file}\")\n",
    "print(f\"   - Filas totales: {len(grid_m)}\")\n",
    "print(f\"   - Filas con Score > 0: {len(grid_m[grid_m['score_final'] > 0])}\")\n",
    "print(f\"   - Media de Terrazas: {grid_m['terrazas_500m'].mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
